{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tlRcuC8DHe3G"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**GEFS Eclipse**\n",
        "<a href=\"https://githubtocolab.com/csteele2/Wx4Colab/blob/master/GEFS_Eclipse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a> <br/>\n",
        "A notebook to download, process, and plot probabilities of sky cover from the Global Ensemble Forecast System (GEFS - aka \"American Ensemble\") for the April 2024 solar eclipse. Uses some code borrowed from [Brian Blaylock](https://github.com/blaylockbk) to more efficiently access partial grib files from [GEFS grib archive on AWS](https://aws.amazon.com/marketplace/pp/prodview-qumzmkzc2acri#resources) for data, and matplotlib, cartopy, and contextily to plot. This was quickly hacked together from other code, so I make no guarantees. Note the quarter-degree files on AWS only go out to 240 hours, so this will only plot that far out. Be sure to click the folder icon on the bar to the left to get your PNGs!<br/>\n",
        "<br/>\n",
        "Caleb Steele - https://github.com/csteele2/Wx4Colab\n",
        "<br/>"
      ],
      "metadata": {
        "id": "CosIaWQBJLd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1 - Install and Import**\n",
        "\n",
        "This will install and import everything we need. You need only run this once per session, then you can make all the changes to the form and make as many plots as you wish without having to rerun this cell (unless your session expires and spins down)."
      ],
      "metadata": {
        "id": "tlRcuC8DHe3G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LWWg2LEd0k5"
      },
      "outputs": [],
      "source": [
        "!pip install ecmwflibs\n",
        "!pip install eccodes\n",
        "!pip install cfgrib\n",
        "!pip install cartopy contextily pyproj pyepsg zarr xarray tqdm\n",
        "\n",
        "from datetime import datetime, timedelta  # our data is time-based\n",
        "import xarray as xr  # easily create hypercubes and store/read from zarrs\n",
        "import numpy as np  # for python stuff that deals with numbers\n",
        "import os, sys, getopt, re  # to manage the temporary files and read in arguments\n",
        "import glob  # to help clean up\n",
        "from urllib.request import urlretrieve # to get files\n",
        "\n",
        "import warnings  # to squash warnings that I have deemed insignificant\n",
        "import requests # just to sniff for a remote file first\n",
        "import time # in case we need to wait for GEFS data\n",
        "\n",
        "from cartopy import crs as ccrs, feature as cfeature\n",
        "import cartopy.geodesic as geodesic\n",
        "import cartopy.io.shapereader as shpreader\n",
        "from cartopy.feature import ShapelyFeature\n",
        "import contextily as cx\n",
        "from pyproj.crs import CRS # to warp maptiles\n",
        "import matplotlib  # to make plots, duh\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patheffects as PathEffects  # to add outline to text, etc.\n",
        "import matplotlib.patches as mpatches  # to make a nicer looking legend vice a colorbar\n",
        "from tqdm.notebook import tqdm # to show progress and minimize printed output\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2 - Edit Form Options & Go!**\n",
        "\n",
        "The cell below has some config things to set. For the curious, you can unhide the code hiding underneath."
      ],
      "metadata": {
        "id": "CEWykHnGHkqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Chose Options\n",
        "#@markdown Select a GEFS Cycle\n",
        "init_date = \"2024-03-29\" #@param {type:\"date\"}\n",
        "init_hour = 18 #@param {type:\"slider\", min:0, max:18, step:6}\n",
        "model_run = datetime.strptime(init_date,'%Y-%m-%d') + timedelta(hours=int(init_hour))\n",
        "#@markdown <br />\n",
        "\n",
        "#@markdown Pick a sky threshold (the NDFD threshold for sunny/clear is 12.5)\n",
        "sky_threshold = 12 # @param {type:\"integer\"}\n",
        "#@markdown <br />\n",
        "\n",
        "#@markdown Pick a map theme\n",
        "map_theme = \"Dark Grey Matter\" #@param [\"Light Shaded Relief\", \"Positron\", \"Dark Matter\", \"Dark Grey Matter\", \"ESRI Light Grey\", \"ESRI Dark Grey\"]\n",
        "if \"Dark\" in map_theme:\n",
        "  font_color='w'\n",
        "  face_color='#272727'\n",
        "else:\n",
        "  font_color = 'k'\n",
        "  face_color = 'w'\n",
        "#@markdown Set the map scale offset from default (i.e. a 1 would scale up one level [make labels bigger])\n",
        "map_scale_offset = \"0\" #@param [\"-2\",\"-1\", \"0\", \"1\",\"2\"]\n",
        "map_zoom_offset = int(map_scale_offset)\n",
        "dom = \"ECONUS\" #@param [\"CONUS\", \"ECONUS\", \"---- WESTERN REGION ----\", \"WR\",\"NR\",\"UT\",\"AZ\",\"SWUS\",\"PNW\", \"---- CENTRAL REGION ----\",\"CR\", \"NP\", \"GL\", \"CUS\", \"CO\", \"---- SOUTHERN REGION ----\", \"SR\", \"TXOK\", \"SE\", \"---- EASTERN REGION ----\", \"ER\", \"NE\"]\n",
        "\n",
        "\n",
        "members = [\"c00\"] + [f\"p{i:02}\" for i in range(1, 31)]\n",
        "members_tqdm = tqdm([\"c00\"] + [f\"p{i:02}\" for i in range(1, 31)])\n",
        "eclipse_valid_times = [datetime(2024, 4, 8, 15, 0), datetime(2024, 4, 8, 18, 0), datetime(2024, 4, 8, 21, 0), datetime(2024, 4, 9, 0, 0)]\n",
        "fh_tds = [t - model_run for t in eclipse_valid_times]\n",
        "fh_list = [int(d.total_seconds() / 3600) for d in fh_tds]\n",
        "\n",
        "sfc_variables = [\"tcdc\"]\n",
        "\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data\")\n",
        "if not os.path.exists(\"tmpcache\"):\n",
        "    os.makedirs(\"tmpcache\")\n",
        "if not os.path.exists(\"shp\"):\n",
        "    os.makedirs(\"shp\")\n",
        "\n",
        "for file in [\"center\", \"upath_hi\"]:\n",
        "  for extension in [\".shp\", \".dbf\", \".prj\", \".shx\"]:\n",
        "    if os.path.exists(f\"shp/{file}{extension}\"):\n",
        "      pass\n",
        "    else:\n",
        "        urlretrieve(f\"https://www.dynamicmeteorology.com/data/2024eclipse_shapefiles/{file}{extension}\", f\"shp/{file}{extension}\")\n",
        "\n",
        "def download_subset(parameter, level, member, forecast_hour, local_filename):\n",
        "    # print(\"   > Downloading a subset of GEFS\")\n",
        "    gribset = \"pgrb2sp25\"\n",
        "    gribfilekey = \"pgrb2s.0p25\"\n",
        "    prefix = f\"gefs.{model_run.strftime('%Y%m%d/%H')}/atmos/{gribset}/\"\n",
        "    local_file = os.path.join(\"tmpcache\", local_filename)\n",
        "    aws_root = f\"https://noaa-gefs-pds.s3.amazonaws.com/{prefix}\"\n",
        "    remote_url = f\"{aws_root}ge{member}.t{model_run.strftime('%Hz')}.{gribfilekey}.f{int(forecast_hour):03}\"\n",
        "    # print(remote_url)\n",
        "    searchStringDict = {\n",
        "        \"tcdc\": \":TCDC:\",\n",
        "    }\n",
        "    # print(searchStringDict[parameter])\n",
        "    search_string = searchStringDict[parameter]\n",
        "    # print(search_string)\n",
        "    idx = remote_url + \".idx\"\n",
        "    r = requests.get(idx)\n",
        "    if not r.ok:\n",
        "        print(\"     ❌ SORRY! Status Code:\", r.status_code, r.reason)\n",
        "        print(f\"      ❌ It does not look like the index file exists: {idx}\")\n",
        "\n",
        "    lines = r.text.split(\"\\n\")\n",
        "    expr = re.compile(search_string)\n",
        "    byte_ranges = {}\n",
        "    for n, line in enumerate(lines, start=1):\n",
        "        # n is the line number (starting from 1) so that when we call for\n",
        "        # `lines[n]` it will give us the next line. (Clear as mud??)\n",
        "\n",
        "        # Use the compiled regular expression to search the line\n",
        "        if expr.search(line):\n",
        "            # aka, if the line contains the string we are looking for...\n",
        "\n",
        "            # Get the beginning byte in the line we found\n",
        "            parts = line.split(\":\")\n",
        "            rangestart = int(parts[1])\n",
        "\n",
        "            # Get the beginning byte in the next line...\n",
        "            if n + 1 < len(lines):\n",
        "                # ...if there is a next line\n",
        "                parts = lines[n].split(\":\")\n",
        "                rangeend = int(parts[1])\n",
        "            else:\n",
        "                # ...if there isn't a next line, then go to the end of the file.\n",
        "                rangeend = \"\"\n",
        "\n",
        "            # Store the byte-range string in our dictionary,\n",
        "            # and keep the line information too so we can refer back to it.\n",
        "            byte_ranges[f\"{rangestart}-{rangeend}\"] = line\n",
        "            # print(line)\n",
        "    for i, (byteRange, line) in enumerate(byte_ranges.items()):\n",
        "\n",
        "        if i == 0:\n",
        "            # If we are working on the first item, overwrite the existing file.\n",
        "            curl = f\"curl -s --range {byteRange} {remote_url} > {local_file}\"\n",
        "        else:\n",
        "            # If we are working on not the first item, append the existing file.\n",
        "            curl = f\"curl -s --range {byteRange} {remote_url} >> {local_file}\"\n",
        "        try:\n",
        "            num, byte, date, var, level, forecast, _ = line.split(\":\")\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # print(f'  Downloading GRIB line [{num:>3}]: variable={var}, level={level}, forecast={forecast}')\n",
        "        os.system(curl)\n",
        "\n",
        "    if os.path.exists(local_file):\n",
        "        # print(f'      ✅ Success! Searched for [{searchStringDict[parameter]}] and got [{len(byte_ranges)}] GRIB fields and saved as {local_file}')\n",
        "        return local_file\n",
        "    else:\n",
        "        print(\n",
        "            print(\n",
        "                f\"      ❌ Unsuccessful! Searched for [{search_string}] in [{idx}] and did not find anything!\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "def get_gefs(parameter, flist=\"default\"):\n",
        "    #print(f\"Downloading {parameter} grids\")\n",
        "    func_start = datetime.now()\n",
        "    if flist == \"default\":\n",
        "        flist = fh_list\n",
        "\n",
        "    for t in [i for i in flist if i <= 240]:\n",
        "        for member in members_tqdm:\n",
        "            members_tqdm.set_description(f\"Downloading {parameter}: (FH{t} / {member})\")\n",
        "            # remote_file = f\"ge{member}.t{model_run.strftime('%Hz')}.pgrb2s.0p25.f{int(t):03}\"\n",
        "            # file_name = prefix+remote_file\n",
        "            # print(file_name)\n",
        "            # uri = f\"simplecache::s3://{bucket}/{file_name}\"\n",
        "            # file = fsspec.open_local(uri, s3={'anon': True}, filecache={'cache_storage':'tmpcache/'})\n",
        "            local_file = f\"tmp_{parameter}_{member}.grib2\"\n",
        "            level = \"surface\"\n",
        "            download_subset(parameter, level, member, t, local_file)\n",
        "            # s3.download_file(bucket, file_name, local_file)\n",
        "\n",
        "            dataset_member = xr.open_dataset(\n",
        "                os.path.join(\"tmpcache\", local_file),\n",
        "                engine=\"cfgrib\",\n",
        "                # backend_kwargs={\"filter_by_keys\": {'typeOfLevel': 'surface'}},\n",
        "            )\n",
        "            # dataset_member = dataset_member[sfc_variables] # only want a few variables\n",
        "            dataset_member = dataset_member.expand_dims(\n",
        "                {\"step\": 1}\n",
        "            )  # need to add this as a dimension so we can append times\n",
        "            dataset_member = dataset_member.expand_dims(\n",
        "                {\"number\": 1}\n",
        "            )  # need to add this as a dimension so we can append members\n",
        "            if member == \"c00\":\n",
        "                dataset = dataset_member\n",
        "            else:\n",
        "                dataset = xr.concat([dataset, dataset_member], dim=\"number\")\n",
        "            # dataset_sfc = dataset_sfc.sel(longitude=slice(-180, -30), latitude=slice(85, 5))\n",
        "            # Now we want to store those x-array objects into a zarr, for fast, lazy access later\n",
        "        if os.path.exists(os.path.join(\"data\", f\"gefs_{parameter}.zarr\")):\n",
        "             dataset.to_zarr(\n",
        "                store=os.path.join(\"data\", f\"gefs_{parameter}.zarr\"),\n",
        "                mode=\"a\",\n",
        "                append_dim=\"step\",\n",
        "            )\n",
        "        else:\n",
        "            dataset.to_zarr(\n",
        "                store=os.path.join(\"data\", f\"gefs_{parameter}.zarr\"), mode=\"w\"\n",
        "            )\n",
        "        try:\n",
        "            tempfiles = glob.glob(os.path.join(\"tmpcache\", f\"tmp_{parameter}*\"), recursive=True)\n",
        "            for tempfile in tempfiles:\n",
        "                os.remove(tempfile)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    func_end = datetime.now()\n",
        "    func_total = func_end - func_start\n",
        "    total_seconds = func_total.total_seconds()\n",
        "    fminutes, fseconds = divmod(total_seconds, 60)\n",
        "    print(f\"{parameter} download complete in: {round(fminutes)}m {round(fseconds)}s\")\n",
        "\n",
        "latloncrs = ccrs.PlateCarree()\n",
        "#proj = ccrs.epsg(3857)\n",
        "if dom == \"CONUS\":\n",
        "  proj = ccrs.AlbersEqualArea(central_longitude=-98.35,\n",
        "                              central_latitude=39.5,\n",
        "                              false_easting=0.0,\n",
        "                              false_northing=0.0,\n",
        "                              standard_parallels=(20.0, 50.0),\n",
        "                              globe=None)\n",
        "else:\n",
        "  proj = ccrs.Mercator.GOOGLE\n",
        "\n",
        "width = 7 # sets figure width value\n",
        "height = 7 # sets figure height value\n",
        "\n",
        "domain_dict = {\n",
        "               \"CONUS\":{\"west\":-123.650,\n",
        "                    \"south\":23.377,\n",
        "                    \"east\":-71.488,\n",
        "                    \"north\":50.924,\n",
        "                    \"zoom_adj\": 0,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"ECONUS\":{\"west\":-104.36,\n",
        "                    \"south\":24.735,\n",
        "                    \"east\":-66.453,\n",
        "                    \"north\":49.755,\n",
        "                    \"zoom_adj\": 0,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"WR\":{\"west\":-126.917,\n",
        "                    \"south\":30.586,\n",
        "                    \"east\":-102.740,\n",
        "                    \"north\":49.755,\n",
        "                    \"zoom_adj\": 1,\n",
        "                     \"legend\":4},\n",
        "\n",
        "               \"UT\":{\"west\":-117.02,\n",
        "                      \"east\":-106.92,\n",
        "                      \"north\":42.13,\n",
        "                      \"south\":36.80,\n",
        "                      \"zoom_adj\": 1,\n",
        "                     \"legend\":4},\n",
        "\n",
        "               \"NR\":{\"west\":-117.5177,\n",
        "                    \"south\":41.9071,\n",
        "                    \"east\":-103.38071,\n",
        "                    \"north\":49.3085,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"PNW\":{\"west\":-125.4510,\n",
        "                    \"south\":41.8754,\n",
        "                    \"east\":-110.9318,\n",
        "                    \"north\":49.5767,\n",
        "                    \"zoom_adj\": 0,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"SWUS\":{\"west\":-125.582,\n",
        "                    \"south\":31.136,\n",
        "                    \"east\":-108.689,\n",
        "                    \"north\":42.859,\n",
        "                    \"zoom_adj\": 0,\n",
        "                    \"legend\":3},\n",
        "\n",
        "               \"AZ\":{\"west\":-115.596,\n",
        "                    \"south\":31.113,\n",
        "                    \"east\":-107.887,\n",
        "                    \"north\":37.446,\n",
        "                    \"zoom_adj\": 0,\n",
        "                    \"legend\":4},\n",
        "\n",
        "\n",
        "               \"CR\":{\"west\":-111.534,\n",
        "                    \"south\":35.118,\n",
        "                    \"east\":-82.263,\n",
        "                    \"north\":49.755,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"NP\":{\"west\":-105.244,\n",
        "                    \"south\":42.173,\n",
        "                    \"east\":-89.426,\n",
        "                    \"north\":49.474,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"GL\":{\"west\":-97.606,\n",
        "                    \"south\":38.735,\n",
        "                    \"east\":-74.916,\n",
        "                    \"north\":49.292,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":3},\n",
        "\n",
        "               \"CUS\":{\"west\":-111.553,\n",
        "                    \"south\":34.794,\n",
        "                    \"east\":-88.533,\n",
        "                    \"north\":46.357,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":3},\n",
        "\n",
        "               \"CO\":{\"west\":-109.5,\n",
        "                    \"south\":36.5,\n",
        "                    \"east\":-101.5,\n",
        "                    \"north\":41.5,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"SR\":{\"west\":-109.758,\n",
        "                    \"south\":23.313,\n",
        "                    \"east\":-78.247,\n",
        "                    \"north\":37.899,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":3},\n",
        "\n",
        "               \"TXOK\":{\"west\":-106.95,\n",
        "                    \"south\":26.06,\n",
        "                    \"east\":-86.76,\n",
        "                    \"north\":37.76,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"SE\":{\"west\":-92.974,\n",
        "                    \"south\":24.578,\n",
        "                    \"east\":-75.1311,\n",
        "                    \"north\":37.390,\n",
        "                    \"zoom_adj\": 1,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"ER\":{\"west\":-85.629,\n",
        "                    \"south\":31.723,\n",
        "                    \"east\":-66.465,\n",
        "                    \"north\":47.676,\n",
        "                    \"zoom_adj\": 0,\n",
        "                    \"legend\":4},\n",
        "\n",
        "               \"NE\":{\"west\":-85.629,\n",
        "                    \"south\":37.654,\n",
        "                    \"east\":-66.00,\n",
        "                    \"north\":47.825,\n",
        "                    \"zoom_adj\": 0,\n",
        "                    \"legend\":4},\n",
        "}\n",
        "\n",
        "west = domain_dict[dom][\"west\"]\n",
        "south = domain_dict[dom][\"south\"]\n",
        "east = domain_dict[dom][\"east\"]\n",
        "north = domain_dict[dom][\"north\"]\n",
        "#map_zoom_offset = domain_dict[dom][\"zoom_adj\"]\n",
        "LLOC = domain_dict[dom][\"legend\"]\n",
        "\n",
        "def blankmap():\n",
        "    global maplayertext1, maplayertext2\n",
        "    print(\" > Initializing map\")\n",
        "    plt.figure(figsize=(width,height),frameon=True, facecolor=face_color)\n",
        "    F = plt.gcf()  # Gets the current figure\n",
        "    ax = plt.axes(projection=proj)\n",
        "\n",
        "  ### Here is where you set up the domain.\n",
        "  ### Want to add another? Just copy the last (elif) one and change the bounds (try to keep it square)\n",
        "  ### Note the attributes are turned OFF on the cx.add_basemap layers IF you have mixed and matched provider sources. \\\n",
        "  ### This is because each attribution goes on top of the other, and thus are manually added so they remain legible.\n",
        "    zoom = (cx.tile._calculate_zoom(west, south, east, north) - map_zoom_offset)\n",
        "\n",
        "    ax.set_extent([west, east, south, north], crs=latloncrs)\n",
        "\n",
        "    print(' > Adding fancy map tiles')\n",
        "    maplayertext2 = \"\"\n",
        "    maylayertext1 = \"\"\n",
        "    if map_theme == \"Light Shaded Relief\":\n",
        "      ax.add_feature(cfeature.LAND, edgecolor='none', facecolor='#FAFAF8', zorder=-2)\n",
        "      cx.add_basemap(ax, source=\"https://basemap.nationalmap.gov/arcgis/rest/services/USGSShadedReliefOnly/MapServer/tile/{z}/{y}/{x}\",\n",
        "                      attribution=False, crs=proj, alpha =0.8, zorder=-1)\n",
        "      maplayertext1 = \"Map tiles: © USGS Earth Resources Observation & Science (EROS) Center: GMTED2010\" #for USGS Hillshade\n",
        "      ax.add_feature(cfeature.OCEAN, edgecolor='none', facecolor='#b3bbbd', zorder=2) # adds fill over the ocean\n",
        "      ax.add_feature(cfeature.LAKES, edgecolor='none', facecolor='#b3bbbd', zorder=2) # adds fill over lakes\n",
        "      cx.add_basemap(ax, source=\"http://services.arcgisonline.com/arcgis/rest/services/Reference/World_Boundaries_and_Places/MapServer/tile/{z}/{y}/{x}\",\n",
        "                      attribution=False, crs=proj, zoom=zoom, zorder=50)\n",
        "      cx.add_basemap(ax, source='http://services.arcgisonline.com/arcgis/rest/services/Reference/World_Transportation/MapServer/tile/{z}/{y}/{x}',\n",
        "                      crs=proj, zoom=zoom, zorder=49)\n",
        "      maplayertext2 = \"Esri, HERE, Garmin, OpenStreetMap contributors\"\n",
        "\n",
        "    elif map_theme == \"Stamen Toner Light\":\n",
        "      cx.add_basemap(ax, source=\"https://tiles.stadiamaps.com/tiles/alidade_smooth/{z}/{x}/{y}{r}.png?api_key=c1f1f8dc-47a0-49e2-bd54-41ad85c19841\", zoom=zoom, zorder=-1, attribution=False, crs=proj)\n",
        "      #cx.add_basemap(ax, source=cx.providers.Stamen.TonerHybrid, zoom=zoom, zorder=49, attribution=False, crs=proj)\n",
        "      maplayertext1 = str(cx.providers.Stadia.AlidadeSmooth.attribution)\n",
        "\n",
        "    elif map_theme == \"Positron\":\n",
        "      cx.add_basemap(ax, source=cx.providers.CartoDB.PositronNoLabels, zorder=-1, attribution=False, crs=proj)\n",
        "      ax.add_feature(cfeature.NaturalEarthFeature('cultural', 'admin_1_states_provinces_lines', '50m', edgecolor='#e5e2e3', facecolor='none', linewidth=0.5, zorder=48, alpha=0.5)) # adds state borders\n",
        "      ax.add_feature(cfeature.COASTLINE, edgecolor=\"#FAFAF8\", facecolor=None, linewidth=0.25, alpha=0.5, zorder=48) # adds coastline (since that isn't included)\n",
        "      ax.add_feature(cfeature.BORDERS, edgecolor=\"#FAFAF8\", facecolor=None, linewidth=0.5, alpha=0.75, zorder=48) # adds country borders (since that isn't included)\n",
        "      cx.add_basemap(ax, source=cx.providers.CartoDB.PositronOnlyLabels, zoom=zoom, zorder=49, attribution=False, crs=proj)\n",
        "      ax.add_feature(cfeature.OCEAN, edgecolor='none', facecolor='#d5dadc', zorder=2) # adds fill over the ocean\n",
        "      ax.add_feature(cfeature.LAKES, edgecolor='none', facecolor='#d5dadc', zorder=2) # adds fill over lakes\n",
        "      maplayertext1 = \"Map tiles: \" + str(cx.providers.CartoDB.Positron.attribution)\n",
        "\n",
        "    elif map_theme == \"Dark Grey Matter\":\n",
        "      ax.add_feature(cfeature.LAND, edgecolor='none', facecolor='#414143', zorder=-2)\n",
        "      ax.add_feature(cfeature.OCEAN, edgecolor='none', facecolor='#232227', zorder=2) # adds fill over the ocean\n",
        "      ax.add_feature(cfeature.LAKES, edgecolor='none', facecolor='#232227', zorder=2) # adds fill over lakes\n",
        "      #cx.add_basemap(ax, source=cx.providers.CartoDB.DarkMatterNoLabels, zorder=-1, attribution=False)\n",
        "      ax.add_feature(cfeature.NaturalEarthFeature('cultural', 'admin_1_states_provinces_lines', '50m', edgecolor='#1c1c1c', facecolor='none', linewidth=0.5, zorder=48, alpha=0.5)) # adds state borders\n",
        "      ax.add_feature(cfeature.COASTLINE, edgecolor='k', facecolor=None, linewidth=0.25, alpha=0.5, zorder=48) # adds coastline (since that isn't included)\n",
        "      ax.add_feature(cfeature.BORDERS, edgecolor='k', facecolor=None, linewidth=0.5, alpha=0.75, zorder=48) # adds country borders (since that isn't included)\n",
        "      cx.add_basemap(ax, source=cx.providers.CartoDB.DarkMatterOnlyLabels, zoom=zoom, zorder=49, attribution=False, crs=proj)\n",
        "      maplayertext1 = \"Map tiles: \" + str(cx.providers.CartoDB.DarkMatter.attribution)\n",
        "\n",
        "    elif map_theme == \"Dark Matter\":\n",
        "      cx.add_basemap(ax, source=cx.providers.CartoDB.DarkMatterNoLabels, zorder=-1, attribution=False, crs=proj)\n",
        "      ax.add_feature(cfeature.NaturalEarthFeature('cultural', 'admin_1_states_provinces_lines', '50m', edgecolor='#1c1c1c', facecolor='none', linewidth=0.5, zorder=48, alpha=0.5)) # adds state borders\n",
        "      ax.add_feature(cfeature.COASTLINE, edgecolor='k', facecolor=None, linewidth=0.25, alpha=0.5, zorder=48) # adds coastline (since that isn't included)\n",
        "      ax.add_feature(cfeature.BORDERS, edgecolor='k', facecolor=None, linewidth=0.5, alpha=0.75, zorder=48) # adds country borders (since that isn't included)\n",
        "      cx.add_basemap(ax, source=cx.providers.CartoDB.DarkMatterOnlyLabels, zoom=zoom, zorder=49, attribution=False, crs=proj)\n",
        "      maplayertext1 = \"Map tiles: \" + str(cx.providers.CartoDB.DarkMatter.attribution)\n",
        "\n",
        "    elif map_theme == \"ESRI Light Grey\":\n",
        "      cx.add_basemap(ax, source='https://server.arcgisonline.com/ArcGIS/rest/services/Canvas/World_Light_Gray_Base/MapServer/tile/{z}/{y}/{x}', zoom=zoom, zorder=-1, crs=proj, attribution=False)\n",
        "      ax.add_feature(cfeature.NaturalEarthFeature('cultural', 'admin_1_states_provinces_lines', '50m', edgecolor='#e4e4e4', facecolor='none', linewidth=0.5, zorder=48)) # adds state borders\n",
        "      ax.add_feature(cfeature.COASTLINE, edgecolor='#efefef', facecolor=None, linewidth=0.25, alpha=0.5, zorder=48) # adds coastline (since that isn't included)\n",
        "      ax.add_feature(cfeature.BORDERS, edgecolor='#efefef', facecolor=None, linewidth=0.5, alpha=0.75, zorder=48) # adds country borders (since that isn't included)\n",
        "      cx.add_basemap(ax, source='https://server.arcgisonline.com/ArcGIS/rest/services/Canvas/World_Light_Gray_Reference/MapServer/tile/{z}/{y}/{x}', zoom=zoom, zorder=49, crs=proj, attribution=False)\n",
        "      maplayertext1 = \"Map tiles: Esri, HERE, Garmin, FAO, NOAA, USGS, © OpenStreetMap contributors, and the GIS User Community\"\n",
        "\n",
        "    elif map_theme == \"ESRI Dark Grey\":\n",
        "      cx.add_basemap(ax, source='https://server.arcgisonline.com/ArcGIS/rest/services/Canvas/World_Dark_Gray_Base/MapServer/tile/{z}/{y}/{x}', zorder=-1, crs=proj, attribution=False)\n",
        "      ax.add_feature(cfeature.NaturalEarthFeature('cultural', 'admin_1_states_provinces_lines', '50m', edgecolor='#363638', facecolor='none', linewidth=0.5, zorder=48, alpha=0.5)) # adds state borders\n",
        "      ax.add_feature(cfeature.COASTLINE, edgecolor='#3f3f3f', facecolor=None, linewidth=0.25, alpha=0.5, zorder=48) # adds coastline (since that isn't included)\n",
        "      ax.add_feature(cfeature.BORDERS, edgecolor='#3f3f3f', facecolor=None, linewidth=0.5, alpha=0.75, zorder=48) # adds country borders (since that isn't included)\n",
        "      cx.add_basemap(ax, source='https://server.arcgisonline.com/ArcGIS/rest/services/Canvas/World_Dark_Gray_Reference/MapServer/tile/{z}/{y}/{x}', zoom=zoom, zorder=49, crs=proj, attribution=False)\n",
        "      maplayertext1 = \"Map tiles: Esri, HERE, Garmin, © OpenStreetMap contributors, and the GIS User Community\"\n",
        "\n",
        "    center_path = ShapelyFeature(shpreader.Reader(\"shp/center.shp\").geometries(),\n",
        "                                ccrs.PlateCarree(), facecolor='none', edgecolor=font_color, linestyle=\"dashed\", linewidth=0.75, zorder=5)\n",
        "    umbra_path = ShapelyFeature(shpreader.Reader(\"shp/upath_hi.shp\").geometries(),\n",
        "                                ccrs.PlateCarree(), facecolor='#0000001A', edgecolor=font_color, linewidth=0.5, zorder=5)\n",
        "    ax.add_feature(center_path)\n",
        "    ax.add_feature(umbra_path)\n",
        "\n",
        "\n",
        "\n",
        "### Set up the plotting function (the thing that actually generates the finished figure)\n",
        "def drawmap(DATA,TITLESTRING,UNITS,LEVS,valid_date):\n",
        "    print(\" > Finishing up map and adding legend\")\n",
        "    F = plt.gcf()  # Gets the current figure\n",
        "    ax = plt.gca()  # Gets the current axes\n",
        "    proxy = [mpatches.Patch(color = pc.get_facecolor()[0]) for pc in DATA.collections]\n",
        "    LLABS = []\n",
        "    for i in range(0, len(LEVS)-1):\n",
        "      label = str(LEVS[i])+\"-\"+str(LEVS[i+1])+UNITS\n",
        "      LLABS.append(label)\n",
        "\n",
        "    proxy = proxy[::-1]\n",
        "    LLABS = LLABS[::-1]\n",
        "\n",
        "    LLABS[0] = \"(High Chance Sunny)\\n\" + LLABS[0]\n",
        "    LLABS[-1] = LLABS[-1] + \"\\n(Low Chance Sunny)\"\n",
        "\n",
        "    l = plt.legend(handles=proxy, labels=LLABS, fontsize='5',fancybox=True, loc=LLOC)\n",
        "    for text in l.get_texts():\n",
        "      text.set_color(font_color)\n",
        "    lframe = l.get_frame()\n",
        "    lframe.set_color(face_color)\n",
        "    l.set_zorder(100)\n",
        "\n",
        "    #artists, labels = DATA.legend_elements()\n",
        "\n",
        "    init_title = model_run.strftime('%HZ %d-%b-%Y')\n",
        "    gefs_text = r\"$\\bf{\"+'GEFS'+\"}$\" +' (Global Ensemble Forecast System) · ' +r\"$\\bf{\"+\"Init\"+\"}$\" +\" \"+ init_title\n",
        "    valid_date_title = valid_date.strftime('%HZ %a\\n %b %d %Y')\n",
        "    title_text = r\"$\\bf{\"+ TITLESTRING +\"}$\" +' (Less Than ' + str(sky_threshold) + r'% Cloud Cover)'\n",
        "\n",
        "    plt.text(0.0,1.03, title_text, transform=ax.transAxes, ha='left', va='bottom', fontsize=9, color=font_color)\n",
        "    plt.text(0.0,1.03, gefs_text, transform=ax.transAxes, ha='left', va='top', fontsize=6, color='grey')\n",
        "    plt.text(1.0,1.03,valid_date_title, transform=ax.transAxes, ha='right', va='center', weight='bold', fontsize=7, color=font_color)\n",
        "\n",
        "    if maplayertext1 != \"\":\n",
        "      if maplayertext2 !=\"\":\n",
        "          plt.text(0.5, -0.009, '%s, %s // Graphic by Caleb Steele with Wx4Colab' % (maplayertext1,maplayertext2),\n",
        "                  transform = ax.transAxes, ha='center', va ='top',fontsize=4,color=font_color, style='italic', zorder=99,\n",
        "                  bbox=dict(facecolor=face_color,edgecolor='none', pad=1.8, alpha=0.65))\n",
        "      else:\n",
        "        plt.text(0.5, -0.009, '%s // Graphic by Caleb Steele with Wx4Colab' % (maplayertext1),\n",
        "                  transform = ax.transAxes, ha='center', va ='top',fontsize=4,color=font_color, style='italic', zorder=99,\n",
        "                  bbox=dict(facecolor=face_color,edgecolor='none', pad=1.8, alpha=0.65))\n",
        "\n",
        "    file_id = 'GEFS_psky_%s_%sT%s' % (dom, model_run.strftime('%Y%m%d%H'), valid_date.strftime('%Y%m%d%H'))\n",
        "\n",
        "    filename = '%s.png' % (file_id)\n",
        "    print(f' > Saving plot as {filename}')\n",
        "    plt.savefig(filename,bbox_inches='tight', facecolor=face_color) # Saves the figure with small margins\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_tcdc_prob():\n",
        "    print(\"Calculating probability and making plot...\")\n",
        "    blankmap()\n",
        "    tcdc = gefs.tcc\n",
        "    #print(f\"St Louis: {gefs.sel(latitude=38.632, longitude=-90.208, method='nearest').tcc.values}\")\n",
        "    thresh_flag = xr.where(tcdc < sky_threshold, 1, 0)\n",
        "    prob_clear = ((thresh_flag.sum(dim=\"number\")) / len(thresh_flag.number.values)) * 100\n",
        "    pclear_plot = plt.contourf(\n",
        "                            gefslons,\n",
        "                            gefslats,\n",
        "                            prob_clear,\n",
        "                            [0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
        "                            cmap=plt.get_cmap(\"RdBu\"),\n",
        "                            #cmap=plt.get_cmap(\"RdYlGn\"),\n",
        "                            alpha=0.75,\n",
        "                            transform=latloncrs,\n",
        "                            transform_first=True,\n",
        "                            antialiased=True\n",
        "                  )\n",
        "\n",
        "    valid_time = model_run + timedelta(hours=gefs.step.values.astype('timedelta64[h]') / np.timedelta64(1, 'h'))\n",
        "    #title = f\"Chance of Sky Cover < {sky_threshold}%\"\n",
        "    title = f\"Chance\\ of\\ Clear\\ Skies\"\n",
        "    units = r'%'\n",
        "    levs = [0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "\n",
        "    drawmap(pclear_plot, title, units, levs, valid_time)\n",
        "\n",
        "if os.path.exists(os.path.join(\"data\", \"gefs_tcdc.zarr\")):\n",
        "  pass\n",
        "else:\n",
        "  get_gefs(\"tcdc\")\n",
        "\n",
        "gefs_ds = xr.open_zarr(os.path.join(\"data\", \"gefs_tcdc.zarr\"))\n",
        "new_lon = []\n",
        "for coord in gefs_ds.longitude:\n",
        "    if coord.values > 180:\n",
        "        new_lon.append(coord.item(0) - 360.0)\n",
        "    else:\n",
        "        new_lon.append(coord.item(0))\n",
        "gefs_ds = gefs_ds.assign_coords(longitude=new_lon)\n",
        "gefs_ds = gefs_ds.sortby(\"longitude\")\n",
        "gefs_ds = gefs_ds.sortby(\"latitude\")\n",
        "\n",
        "matplotlib.rcParams['figure.dpi'] = 200\n",
        "for fh in fh_tds:\n",
        "  if fh > timedelta(hours=240):\n",
        "    break\n",
        "  gefs = gefs_ds.sel(step=fh, latitude=slice(south - 5, north + 5), longitude=slice(west - 5, east + 10))\n",
        "  gefslons, gefslats = np.meshgrid(gefs.longitude.values, gefs.latitude.values)\n",
        "  plot_tcdc_prob()\n"
      ],
      "metadata": {
        "id": "3MUHbyGLhvYD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}